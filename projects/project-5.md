---
layout: default
title: Active robot perception
description: Active perception strategies for object pose estimation
---

Keywords: active robot perception; point cloud processing; object pose estimation; 

The key differences between this project and the NBV project are:
1. Point clouds are analyzed using general quality and quantity criteria
2. Potential sensor views are found by formulating and solving optimization problems
3. Robot inverse kinematics are also solved through optimizations
<br/>
<center>
<img src="../images/activePerception.png"/>
</center>
<br/>
The sensor views (a) and robot poses (b) to collect point clouds after point cloud analysis, and the collected point clouds (c).
<br/>
<center>
<img src="../images/active-perception-quality.png" width="480" height="270"/>
</center>
<br/>
The generated robot pose (a) to collect point clouds based on the active robot perception framework and the collected point clouds (b).
<br/>
<center>
<img src="../images/active-perception-quantity.png" width="480" height="270"/>
</center>
<br/>
The details of the methods are included in a paper, which is currently under review. 

[Back to main](https://jhugj.github.io/web-repo/)